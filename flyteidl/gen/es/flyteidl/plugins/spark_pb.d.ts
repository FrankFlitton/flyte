// @generated by protoc-gen-es v1.4.2 with parameter "target=js+dts+ts,keep_empty_files=false"
// @generated from file flyteidl/plugins/spark.proto (package flyteidl.plugins, syntax proto3)
/* eslint-disable */
// @ts-nocheck

import type { BinaryReadOptions, FieldList, JsonReadOptions, JsonValue, PartialMessage, PlainMessage, Struct } from "@bufbuild/protobuf";
import { Message, proto3 } from "@bufbuild/protobuf";

/**
 * @generated from message flyteidl.plugins.SparkApplication
 */
export declare class SparkApplication extends Message<SparkApplication> {
  constructor(data?: PartialMessage<SparkApplication>);

  static readonly runtime: typeof proto3;
  static readonly typeName = "flyteidl.plugins.SparkApplication";
  static readonly fields: FieldList;

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): SparkApplication;

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): SparkApplication;

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): SparkApplication;

  static equals(a: SparkApplication | PlainMessage<SparkApplication> | undefined, b: SparkApplication | PlainMessage<SparkApplication> | undefined): boolean;
}

/**
 * @generated from enum flyteidl.plugins.SparkApplication.Type
 */
export declare enum SparkApplication_Type {
  /**
   * @generated from enum value: PYTHON = 0;
   */
  PYTHON = 0,

  /**
   * @generated from enum value: JAVA = 1;
   */
  JAVA = 1,

  /**
   * @generated from enum value: SCALA = 2;
   */
  SCALA = 2,

  /**
   * @generated from enum value: R = 3;
   */
  R = 3,
}

/**
 * Custom Proto for Spark Plugin.
 *
 * @generated from message flyteidl.plugins.SparkJob
 */
export declare class SparkJob extends Message<SparkJob> {
  /**
   * @generated from field: flyteidl.plugins.SparkApplication.Type applicationType = 1;
   */
  applicationType: SparkApplication_Type;

  /**
   * @generated from field: string mainApplicationFile = 2;
   */
  mainApplicationFile: string;

  /**
   * @generated from field: string mainClass = 3;
   */
  mainClass: string;

  /**
   * @generated from field: map<string, string> sparkConf = 4;
   */
  sparkConf: { [key: string]: string };

  /**
   * @generated from field: map<string, string> hadoopConf = 5;
   */
  hadoopConf: { [key: string]: string };

  /**
   * Executor path for Python jobs.
   *
   * @generated from field: string executorPath = 6;
   */
  executorPath: string;

  /**
   * Databricks job configuration.
   * Config structure can be found here. https://docs.databricks.com/dev-tools/api/2.0/jobs.html#request-structure.
   *
   * @generated from field: google.protobuf.Struct databricksConf = 7;
   */
  databricksConf?: Struct;

  /**
   * Databricks access token. https://docs.databricks.com/dev-tools/api/latest/authentication.html
   * This token can be set in either flytepropeller or flytekit.
   *
   * @generated from field: string databricksToken = 8;
   */
  databricksToken: string;

  /**
   * Domain name of your deployment. Use the form <account>.cloud.databricks.com.
   * This instance name can be set in either flytepropeller or flytekit.
   *
   * @generated from field: string databricksInstance = 9;
   */
  databricksInstance: string;

  constructor(data?: PartialMessage<SparkJob>);

  static readonly runtime: typeof proto3;
  static readonly typeName = "flyteidl.plugins.SparkJob";
  static readonly fields: FieldList;

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): SparkJob;

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): SparkJob;

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): SparkJob;

  static equals(a: SparkJob | PlainMessage<SparkJob> | undefined, b: SparkJob | PlainMessage<SparkJob> | undefined): boolean;
}

